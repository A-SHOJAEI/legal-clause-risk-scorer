# Legal Clause Risk Scorer - Ablation Study Configuration
#
# This configuration disables key novel components to measure their impact:
# 1. Clause-specific multi-head attention disabled
# 2. Attention pooling replaced with mean pooling
# 3. Reduced model capacity for comparison
#
# Use this to demonstrate the contribution of the novel architectural components.

# Data Configuration (same as default)
data:
  cuad_dataset: "cuad"
  ledgar_dataset: "lexlms/ledgar"
  max_sequence_length: 512
  truncation: true
  padding: "max_length"
  train_split: 0.7
  val_split: 0.15
  test_split: 0.15

  risk_categories:
    termination_clauses:
      weight: 0.25
      keywords: ["terminate", "dismissal", "at-will", "without cause"]
    non_compete:
      weight: 0.20
      keywords: ["non-compete", "restraint", "solicitation", "competitor"]
    intellectual_property:
      weight: 0.20
      keywords: ["ip", "intellectual property", "invention", "patent", "copyright"]
    confidentiality:
      weight: 0.15
      keywords: ["confidential", "nda", "proprietary", "trade secret"]
    compensation_terms:
      weight: 0.10
      keywords: ["salary", "bonus", "commission", "overtime", "benefits"]
    dispute_resolution:
      weight: 0.10
      keywords: ["arbitration", "mediation", "jurisdiction", "governing law"]

# Model Configuration - ABLATION: Simplified architecture
model:
  base_model: "microsoft/deberta-v3-base"
  embedding_model: "sentence-transformers/all-MiniLM-L6-v2"

  # ABLATION: Same number of labels
  num_labels: 3

  # ABLATION: Standard dropout (no change)
  dropout: 0.1

  # ABLATION: Same hidden size
  hidden_size: 768

  # ABLATION: Disable clause-specific attention
  use_clause_attention: false

  # ABLATION: Use simple mean pooling instead of attention pooling
  use_attention_pooling: false

  # ABLATION: Simpler task heads (single layer instead of multi-layer)
  simple_heads: true

  risk_score_bins: 10
  classification_threshold: 0.5

# Training Configuration (same as default to ensure fair comparison)
training:
  batch_size: 16
  learning_rate: 0.00002
  num_epochs: 10
  warmup_steps: 500
  weight_decay: 0.01

  optimizer: "AdamW"
  scheduler: "linear"
  gradient_accumulation_steps: 1
  max_grad_norm: 1.0

  early_stopping_patience: 3
  early_stopping_metric: "eval_f1"
  early_stopping_mode: "max"

  save_steps: 1000
  eval_steps: 500
  logging_steps: 100
  save_total_limit: 3

  fp16: true
  use_cuda: true
  dataloader_num_workers: 4

  # Same loss weighting
  classification_weight: 1.0
  regression_weight: 1.0

# Evaluation Configuration
evaluation:
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1"
    - "roc_auc"
    - "mae"

  targets:
    clause_detection_f1: 0.82
    risk_score_mae: 1.2
    unfavorable_term_recall: 0.88

# MLflow Configuration
mlflow:
  experiment_name: "legal_clause_risk_scorer_ablation"
  tracking_uri: "mlruns"
  artifact_location: "artifacts"

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/training_ablation.log"

# Random Seeds for Reproducibility
random_seed: 42
torch_seed: 42
numpy_seed: 42
transformers_seed: 42

# Output Paths
paths:
  data_dir: "data"
  models_dir: "models/ablation"
  logs_dir: "logs"
  cache_dir: ".cache"
  outputs_dir: "outputs/ablation"
